# -*- coding: utf-8 -*-
"""VGG16_Model_Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZW6AiV61Mn27yuZPWrTQPcOv9ZlzCU5T
"""

# Core Libraries
import numpy as np  # For numerical operations
import pandas as pd  # For data manipulation
from google.colab import drive

# Deep Learning
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

# Data Visualization
import matplotlib.pyplot as plt

import seaborn as sns
from sklearn.metrics import confusion_matrix

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

# OS and Warnings
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress unnecessary TensorFlow warnings

"""VGG16 MODEL ARCHITECTURE and Compilng the model"""

# Load VGG16 model without the top layer (pre-trained on ImageNet)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))

# Freeze the layers of the VGG16 model
base_model.trainable = False

# Build the model by adding custom layers
VGG16_model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3, activation='softmax')  # 3 output classes
])

# Compile the model
VGG16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


# Print model summary
VGG16_model.summary()

"""Training VGG16 Model"""

EPOCHS = 10  # Adjust as needed

history_vgg = VGG16_model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)

"""Accuracy and Loss Plot"""

# Plot accuracy
plt.figure(figsize=(12, 6))

# Plot training and validation accuracy
plt.subplot(1, 2, 1)
plt.plot(history_vgg.history['accuracy'], label='Training Accuracy')
plt.plot(history_vgg.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history_vgg.history['loss'], label='Training Loss')
plt.plot(history_vgg.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()

"""Predictions"""

for images_batch, labels_batch in test_ds.take(1):
    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()

    print("First image to predict:")
    plt.imshow(first_image)
    plt.axis("off")

    actual_index = np.argmax(first_label)  # since it's one-hot encoded
    print("Actual label:", class_names[actual_index])

    batch_prediction = VGG16_model.predict(images_batch)
    predicted_index = np.argmax(batch_prediction[0])
    print("Predicted label:", class_names[predicted_index])

"""Predicting a batch of images"""

def predict(VGG16_model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    VGG16_predictions =VGG16_model.predict(img_array)

    VGG16_predicted_class = class_names[np.argmax(VGG16_predictions[0])]
    confidence = round(100 * (np.max(VGG16_predictions[0])), 2)
    return VGG16_predicted_class, confidence

plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)

        image_np = images[i].numpy().astype("uint8")
        plt.imshow(image_np)

        VGG16_predicted_class, confidence = predict(VGG16_model, image_np)
        actual_class = class_names[np.argmax(labels[i].numpy())]  # decode one-hot

        plt.title(f"Actual: {actual_class}\nPredicted: {VGG16_predicted_class}\nConfidence: {confidence}%", fontsize=10)
        plt.axis("off")

plt.tight_layout()
plt.show()

"""Analysis-Confusion Matrix"""

# Initialize lists to store the true labels and predicted labels
y_true2 = []
y_pred2 = []

# Loop through the test dataset and get predictions
for images_batch, labels_batch in test_ds:
    # Predict labels using the model
    VGG16_batch_predictions = VGG16_model.predict(images_batch)
    VGG16_predicted_labels = np.argmax(VGG16_batch_predictions, axis=1)  # Get the predicted class labels (indices)

    # Convert one-hot encoded labels to class indices
    true_labels = np.argmax(labels_batch.numpy(), axis=1)



    # Append the true and predicted labels to the lists
    y_true2.extend(true_labels)
    y_pred2.extend(VGG16_predicted_labels)

# Compute confusion matrix
cm1 = confusion_matrix(y_true2, y_pred2)

# Plot confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm1, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""Calculating the metrics"""

# Calculate precision, recall, f1-score, and accuracy
precision = precision_score(y_true2, y_pred2, average='weighted')  # Change 'weighted' to 'micro' or 'macro' if needed
recall = recall_score(y_true2, y_pred2, average='weighted')
f1 = f1_score(y_true2, y_pred2, average='weighted')
accuracy = accuracy_score(y_true2, y_pred2)

# Print the metrics
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")
print(f"Accuracy: {accuracy}")

"""Saving the Model as .keras"""

# Create a directory in Google Drive to save the model (optional)
VGG16_model_save_path = '/content/drive/MyDrive/ds_plantleaves_potato'  # Adjust the path as needed
os.makedirs(VGG16_model_save_path, exist_ok=True)

# Save the model
VGG16_model_version = 1
VGG16_model.save(os.path.join(VGG16_model_save_path, f'VGG16_model_{VGG16_model_version}.keras'))